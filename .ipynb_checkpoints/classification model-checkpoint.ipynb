{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3df8045",
   "metadata": {},
   "source": [
    " # <font color='A6290E'> Employee Classification model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff04cc15",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9dd38aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas_profiling import ProfileReport\n",
    "# Sklearn classification imports\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import f1_score,roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "import imblearn.over_sampling\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1f2dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c0271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install imblearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef88cdc4",
   "metadata": {},
   "source": [
    "## 2. Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e53d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "Data= pd.read_csv('WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "# prof = ProfileReport(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18775b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#undarstand data\n",
    "# prof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdafcbbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208bf15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a242dea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642a71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d33000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Over18'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8541b3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the data\n",
    "Data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['EducationField'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6d7a8764",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Attrition = Data['Attrition'].map({'Yes': 1, 'No': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "741cf707",
   "metadata": {},
   "outputs": [],
   "source": [
    "##drop unwanted columns\n",
    "\n",
    "Data = Data.drop(columns=['EmployeeNumber','EmployeeCount','Over18','StandardHours','TotalWorkingYears','MonthlyIncome','PerformanceRating','YearsAtCompany','StockOptionLevel','JobRole'])\n",
    "Baseline_data = Data[['Age','Attrition', 'DailyRate',\n",
    "       'DistanceFromHome', 'Education', 'EnvironmentSatisfaction', 'HourlyRate',\n",
    "       'JobInvolvement', 'JobLevel', 'JobSatisfaction','MonthlyRate', 'NumCompaniesWorked',\n",
    "       'PercentSalaryHike',\n",
    "       'RelationshipSatisfaction', 'TrainingTimesLastYear', 'WorkLifeBalance',\n",
    "        'YearsInCurrentRole', 'YearsSinceLastPromotion','YearsWithCurrManager']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "687cb094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19479</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24907</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2396</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1392</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23159</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16632</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12290</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>613</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21457</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5174</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1023</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13243</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>628</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10228</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Attrition  DailyRate  DistanceFromHome  Education  \\\n",
       "0      41          1       1102                 1          2   \n",
       "1      49          0        279                 8          1   \n",
       "2      37          1       1373                 2          2   \n",
       "3      33          0       1392                 3          4   \n",
       "4      27          0        591                 2          1   \n",
       "...   ...        ...        ...               ...        ...   \n",
       "1465   36          0        884                23          2   \n",
       "1466   39          0        613                 6          1   \n",
       "1467   27          0        155                 4          3   \n",
       "1468   49          0       1023                 2          3   \n",
       "1469   34          0        628                 8          3   \n",
       "\n",
       "      EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                           2          94               3         2   \n",
       "1                           3          61               2         2   \n",
       "2                           4          92               2         1   \n",
       "3                           4          56               3         1   \n",
       "4                           1          40               3         1   \n",
       "...                       ...         ...             ...       ...   \n",
       "1465                        3          41               4         2   \n",
       "1466                        4          42               2         3   \n",
       "1467                        2          87               4         2   \n",
       "1468                        4          63               2         2   \n",
       "1469                        2          82               4         2   \n",
       "\n",
       "      JobSatisfaction  MonthlyRate  NumCompaniesWorked  PercentSalaryHike  \\\n",
       "0                   4        19479                   8                 11   \n",
       "1                   2        24907                   1                 23   \n",
       "2                   3         2396                   6                 15   \n",
       "3                   3        23159                   1                 11   \n",
       "4                   2        16632                   9                 12   \n",
       "...               ...          ...                 ...                ...   \n",
       "1465                4        12290                   4                 17   \n",
       "1466                1        21457                   4                 15   \n",
       "1467                2         5174                   1                 20   \n",
       "1468                2        13243                   2                 14   \n",
       "1469                3        10228                   2                 12   \n",
       "\n",
       "      RelationshipSatisfaction  TrainingTimesLastYear  WorkLifeBalance  \\\n",
       "0                            1                      0                1   \n",
       "1                            4                      3                3   \n",
       "2                            2                      3                3   \n",
       "3                            3                      3                3   \n",
       "4                            4                      3                3   \n",
       "...                        ...                    ...              ...   \n",
       "1465                         3                      3                3   \n",
       "1466                         1                      5                3   \n",
       "1467                         2                      0                3   \n",
       "1468                         4                      3                2   \n",
       "1469                         1                      3                4   \n",
       "\n",
       "      YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                      4                        0                     5  \n",
       "1                      7                        1                     7  \n",
       "2                      0                        0                     0  \n",
       "3                      7                        3                     0  \n",
       "4                      2                        2                     2  \n",
       "...                  ...                      ...                   ...  \n",
       "1465                   2                        0                     3  \n",
       "1466                   7                        1                     7  \n",
       "1467                   2                        0                     3  \n",
       "1468                   6                        0                     8  \n",
       "1469                   3                        1                     2  \n",
       "\n",
       "[1470 rows x 19 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Baseline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2befdfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#analyz the relationship \n",
    "corlation = Data.corr()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7543c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(corlation,xticklabels=corlation.columns,yticklabels=corlation.columns,annot=True)\n",
    "plt.gcf().set_size_inches(20, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597e6bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc2819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.relplot(X = 'JobSatisfaction',Y = 'JobRole',hue='Gender' ,data=Data)\n",
    "# sns.distplot(Data['Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25423631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Data['Attrition'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d7fd466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Attrition</th>\n",
       "      <th>DailyRate</th>\n",
       "      <th>DistanceFromHome</th>\n",
       "      <th>Education</th>\n",
       "      <th>EnvironmentSatisfaction</th>\n",
       "      <th>HourlyRate</th>\n",
       "      <th>JobInvolvement</th>\n",
       "      <th>JobLevel</th>\n",
       "      <th>JobSatisfaction</th>\n",
       "      <th>MonthlyRate</th>\n",
       "      <th>NumCompaniesWorked</th>\n",
       "      <th>PercentSalaryHike</th>\n",
       "      <th>RelationshipSatisfaction</th>\n",
       "      <th>TrainingTimesLastYear</th>\n",
       "      <th>WorkLifeBalance</th>\n",
       "      <th>YearsInCurrentRole</th>\n",
       "      <th>YearsSinceLastPromotion</th>\n",
       "      <th>YearsWithCurrManager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1102</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>94</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>19479</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>279</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>24907</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1373</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2396</td>\n",
       "      <td>6</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>1392</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>23159</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>591</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16632</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>884</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>12290</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "      <td>613</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21457</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5174</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1468</th>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>1023</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>63</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13243</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1469</th>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>628</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>82</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10228</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1470 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age  Attrition  DailyRate  DistanceFromHome  Education  \\\n",
       "0      41          1       1102                 1          2   \n",
       "1      49          0        279                 8          1   \n",
       "2      37          1       1373                 2          2   \n",
       "3      33          0       1392                 3          4   \n",
       "4      27          0        591                 2          1   \n",
       "...   ...        ...        ...               ...        ...   \n",
       "1465   36          0        884                23          2   \n",
       "1466   39          0        613                 6          1   \n",
       "1467   27          0        155                 4          3   \n",
       "1468   49          0       1023                 2          3   \n",
       "1469   34          0        628                 8          3   \n",
       "\n",
       "      EnvironmentSatisfaction  HourlyRate  JobInvolvement  JobLevel  \\\n",
       "0                           2          94               3         2   \n",
       "1                           3          61               2         2   \n",
       "2                           4          92               2         1   \n",
       "3                           4          56               3         1   \n",
       "4                           1          40               3         1   \n",
       "...                       ...         ...             ...       ...   \n",
       "1465                        3          41               4         2   \n",
       "1466                        4          42               2         3   \n",
       "1467                        2          87               4         2   \n",
       "1468                        4          63               2         2   \n",
       "1469                        2          82               4         2   \n",
       "\n",
       "      JobSatisfaction  MonthlyRate  NumCompaniesWorked  PercentSalaryHike  \\\n",
       "0                   4        19479                   8                 11   \n",
       "1                   2        24907                   1                 23   \n",
       "2                   3         2396                   6                 15   \n",
       "3                   3        23159                   1                 11   \n",
       "4                   2        16632                   9                 12   \n",
       "...               ...          ...                 ...                ...   \n",
       "1465                4        12290                   4                 17   \n",
       "1466                1        21457                   4                 15   \n",
       "1467                2         5174                   1                 20   \n",
       "1468                2        13243                   2                 14   \n",
       "1469                3        10228                   2                 12   \n",
       "\n",
       "      RelationshipSatisfaction  TrainingTimesLastYear  WorkLifeBalance  \\\n",
       "0                            1                      0                1   \n",
       "1                            4                      3                3   \n",
       "2                            2                      3                3   \n",
       "3                            3                      3                3   \n",
       "4                            4                      3                3   \n",
       "...                        ...                    ...              ...   \n",
       "1465                         3                      3                3   \n",
       "1466                         1                      5                3   \n",
       "1467                         2                      0                3   \n",
       "1468                         4                      3                2   \n",
       "1469                         1                      3                4   \n",
       "\n",
       "      YearsInCurrentRole  YearsSinceLastPromotion  YearsWithCurrManager  \n",
       "0                      4                        0                     5  \n",
       "1                      7                        1                     7  \n",
       "2                      0                        0                     0  \n",
       "3                      7                        3                     0  \n",
       "4                      2                        2                     2  \n",
       "...                  ...                      ...                   ...  \n",
       "1465                   2                        0                     3  \n",
       "1466                   7                        1                     7  \n",
       "1467                   2                        0                     3  \n",
       "1468                   6                        0                     8  \n",
       "1469                   3                        1                     2  \n",
       "\n",
       "[1470 rows x 19 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Baseline_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ea0b54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       1\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1465    0\n",
       "1466    0\n",
       "1467    0\n",
       "1468    0\n",
       "1469    0\n",
       "Name: Attrition, Length: 1470, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Attrition']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d5c9fa",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Models\n",
    "\n",
    "### A. Baseline model (KNN and Logistic Regression )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "642ac39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Split data to 60% Training set and 20% Valid set 20% Teset set\n",
    "# def split_data(df_x, df_y): \n",
    "#     #Split to 80% Training set and 20% Teset set\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(df_x, df_y, test_size= 0.2, random_state=42)\n",
    "#     #Split to 75% Training set and 25% Teset set\n",
    "#     X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size= 0.25, random_state=42)\n",
    "#     return X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "\n",
    "X_train_Base, X_test_Base, y_train_Base, y_test_Base = train_test_split(Baseline_data, Data['Attrition'], test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "c0b79fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 0.83\n",
      "Test score : 0.86 \n"
     ]
    }
   ],
   "source": [
    "# knn beasline model1\n",
    "# Train on training set, and Test on testing set\n",
    "knn = KNeighborsClassifier(n_neighbors=9)\n",
    "knn.fit(X_train_Base, y_train_Base)\n",
    "print(\"Training score : {:.2f}\".format(knn.score(X_train_Base, y_train_Base)))\n",
    "y_pred_knn = knn.predict(X_test_Base)\n",
    "print(\"Test score : {:.2f} \".format(accuracy_score(y_test_Base, y_pred_knn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "7c529943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834013605442177\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.98      0.92       320\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.86       368\n",
      "   macro avg       0.43      0.49      0.46       368\n",
      "weighted avg       0.75      0.86      0.80       368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scores = cross_val_score(knn,Baseline_data, Data['Attrition'], cv=10, scoring='accuracy')\n",
    "print(np.mean(scores))\n",
    "print(classification_report(y_test_Base, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "id": "f326b259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score : 0.83\n",
      "0.8489795918367345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression beasline model2\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_Base, y_train_Base)\n",
    "print(\"Training score : {:.2f}\".format(logreg.score(X_train_Base, y_train_Base)))\n",
    "scores = cross_val_score(logreg,Baseline_data, Baseline_data['Attrition'], cv=10, scoring='accuracy')\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "id": "01ed2ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.87\n"
     ]
    }
   ],
   "source": [
    "y_pred_Base = logreg.predict(X_test_Base)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test_Base, y_test_Base)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "id": "935e97fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93       320\n",
      "           1       0.00      0.00      0.00        48\n",
      "\n",
      "    accuracy                           0.87       368\n",
      "   macro avg       0.43      0.50      0.47       368\n",
      "weighted avg       0.76      0.87      0.81       368\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# report \n",
    "print(classification_report(y_test_Base, y_pred_Base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4e131",
   "metadata": {},
   "source": [
    "### B. Class inbalancemnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "id": "39602fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Value count')"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(Data['Attrition'], color = \"green\")\n",
    "plt.title(\"Check Class inbalancemnet\")\n",
    "plt.xlabel('Attrition')\n",
    "plt.ylabel('Value count')\n",
    "# Data['Attrition'].hist(color:\"green\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37c0b0f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1233\n",
       "1     237\n",
       "Name: Attrition, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data['Attrition'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c4a054",
   "metadata": {},
   "source": [
    "### C. Logistic Regression with Downsampling and dummy varibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "adcf9aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(Data_1):\n",
    "    DownSample = imblearn.under_sampling.RandomUnderSampler()\n",
    "    X, y = DownSample.fit_resample(Data_1.drop(['Attrition'], axis=1) , Data_1['Attrition'] ) \n",
    "\n",
    "    SampledData = pd.concat([X,y], axis=1)\n",
    "    return SampledData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "77db7d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BalanceLogreg(X_train, X_test, y_train, y_test):    \n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))\n",
    "    # report \n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "17e44a8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.63\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60        59\n",
      "           1       0.62      0.70      0.66        60\n",
      "\n",
      "    accuracy                           0.63       119\n",
      "   macro avg       0.63      0.63      0.63       119\n",
      "weighted avg       0.63      0.63      0.63       119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "SampledData = downsample(Baseline_data)\n",
    "# SampledData.Attrition.drop_duplicates().T\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(SampledData.drop(columns='Attrition',axis=1), SampledData['Attrition'], test_size=0.25, random_state=42)\n",
    "BalanceLogreg(X_train1, X_test1, y_train1, y_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "3e91f7ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression classifier on test set: 0.61\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.61      0.61        59\n",
      "           1       0.61      0.60      0.61        60\n",
      "\n",
      "    accuracy                           0.61       119\n",
      "   macro avg       0.61      0.61      0.61       119\n",
      "weighted avg       0.61      0.61      0.61       119\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "Dummy_Data = pd.get_dummies(Data) \n",
    "# Dummy_Data\n",
    "Sampled_Dummy_Data = downsample(Dummy_Data)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(Sampled_Dummy_Data.drop(columns='Attrition',axis=1), Sampled_Dummy_Data['Attrition'], test_size=0.25, random_state=42)\n",
    "BalanceLogreg(X_train2, X_test2, y_train2, y_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c0edd",
   "metadata": {},
   "source": [
    "### D. Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "8ea9650d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Testing : 0.6722689075630253\n",
      "Accuracy : 0.614 (0.033)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68        59\n",
      "           1       0.69      0.63      0.66        60\n",
      "\n",
      "    accuracy                           0.67       119\n",
      "   macro avg       0.67      0.67      0.67       119\n",
      "weighted avg       0.67      0.67      0.67       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_dt_a = DecisionTreeClassifier()\n",
    "model_dt_a.fit(X_train2, y_train2)\n",
    "print(model_dt_a.score(X_train2, y_train2))\n",
    "\n",
    "predictions_dt_a = model_dt_a.predict(X_test2)\n",
    "print(\"Testing :\", accuracy_score(y_test2, predictions_dt_a))\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=35)\n",
    "n_scores = cross_val_score(model_dt_a, Sampled_Dummy_Data.drop(columns='Attrition',axis=1), Sampled_Dummy_Data['Attrition'], scoring='accuracy')\n",
    "# report performance\n",
    "print('Accuracy : %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "print(classification_report(y_test2, predictions_dt_a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "d1413883",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build a decision tree model\n",
    "model_dt = DecisionTreeClassifier()\n",
    "# print(len(X_train1), len(y_train1))\n",
    "path = model_dt.cost_complexity_pruning_path(X_train2, y_train2)\n",
    "ccp_alphas, impurities = path.ccp_alphas, path.impurities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "faa3a024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Total Impurity vs effective alpha for training set')"
      ]
     },
     "execution_count": 648,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAm1UlEQVR4nO3debxcdX3/8dc7lwSumHCFBJpcloSlYJAlEDahFqg2QKEJyK7FWi2gRUR/LEF5KBYtINWqLYpRQVwI0AApFUpUwFoRZDGQsEUCCOSGJSxhkUC2z++PcyaZTGbmnrn3nlnfz8djHnfmbPOZM+eez5zvdhQRmJlZ5xrW6ADMzKyxnAjMzDqcE4GZWYdzIjAz63BOBGZmHc6JwMyswzkRNIikkLR9o+Poj6S/kLSg0XHUQtKXJb0o6bn09ZGSnpH0hqRJQ/g+Ddk3tRw7Q3mcSdpf0mPpfpw2FNscLEkfkvTzoV6208j9CNYl6Y2il+8A3gZWpa9PiYifllnnQOAnEbFlDe8TwA4RsbDMvF+l2/t+9sjrQ9IfgY9HxC8bHUs5krYC/gBsExEvpNMeBz4bEf81yG1X/M7qqZY4hjJmSbcCN0bENwe7rXR7PwQWRcR5Q7G9ViNpPPAkMDwiVjYylg0a+ebNKCLeWXje7Ce9vEnaoNEH6ABsA7xUSAJF0x5qUDztZMD7cSDHUosef60pIvyo8AD+CLw/fb4h8A1gcfr4RjptY2AZsBp4I32MA/YG7gSWAs8C/wGMKNp2ANtXeN9fkSQggAOBRcDZwAvptqYBh5H88n0Z+FzRuucDs4BrgNeB3wO7VXpf4IfAl0ve6xzgOeDHhWnp/B+nn3NZ+jnPBm4CPlUS/zxgWpnPdQtwWsm0B4CjAAH/ln7GV9NtvKfC/tkE+EG6L/qALwNdwPtLvouZ6d8A/gQ8nq4/DrgOWELyi+z0om13AZ8DHk/3333AVsCvi7bzBnBcyb6ZDswqifObwLeqxVzh82U+dtLv7zLgF2m8/0tyNVS87KnAY8ArwKWsLQnYDrgNeAl4Efgp0FMhpsdLvvsN0/14I8kxuBD4xzLH4U+A10iP56L5JwMrgOXp9v676H/unPT7f5vkx+r0ou/jYeDIou38PfCbjJ+3lmW7gK+l++VJ4LR0+Q0q7J9z0u/1dWAB8Ffp9GFF8b8EXAtsms57Ot1m4byxX8POdY1641Z4sG4i+GfgLmBzYAzwW+CCdN6BpCeEonX3BPZND+TxwCPAGSUHYdZEsBL4AjAc+EeSE9hVwEhgZ+AtYNt0+fPTf7Cj0+XPZO3l53rvy/qJYCVwMck/enfpZyveJ+nrY4HfFb3eLT3gR5T5XCcBdxS9nkhystsQmEJy0u0hSQrvBsZW2D+zge+SJOHNgbtJiu0qfRfFJ85h6ft8ARgBbAs8AUxJ558FzAd2TOPYDdiswr5b814kv5bfBEalr7tITuL79hdzmc+X+dhJv7/Xgfel+/GbrH+y+1m6X7cmOXYOSedtD3wgXW8MSbL7Rpb/h/T1/wLfBjYCdk+3XTgBnk9yHE5L93l3me39kPTYK3mP+0mSb3c67RiSpDOMJAH/qXBsUP7kXunz1rLsqSRJZ0vgXcAvqZAISI6VZ4Bx6evxwHbp8zNIzhtbpvv5u8DMouUqJpe6nusaHUAzP1g3ETwOHFY0bwrwx/T5gZScfMps6wzghpKDMGsiWEb665Hk5B/APkXL30f6Czz9B7yraN4wkhPSX5R7X9ZPBMuBjYrmr/PZWP9ksCHJL8Id0tf/Cny7wucaSfJPvE36+ivA5enzg0mucPYFhlXZj1uQ/FLsLpp2AnB7pe+CdU+c+wBPl8w/F7gifb4AmFrhvSsmgvT1b4CT0ucfYO0VSNWYMxyHFY+d9Pu7umjeO0nqtLYqWvaAovnXAtMrvM80YG7G/4et0vcZWTT/QuCHRcfhr/v5XGuOvZL3+Id+1ru/8B1R/uRe9vPWuOxtFCVqkqvNSolge5Ir2feT/uAqmvcIaXJMX48lSZCFJN8UicCthrIbBzxV9PqpdFpZkv5c0s8kPSfpNeBfgNEDfO+XIqJQYb0s/ft80fxlJCeAgmcKTyJiNUlxT8VYSyyJiLeyBhYRb5P8A31Y0jCSE9yPKyz7OklR0vHppONJiiOIiNtIikAuBZ6XNEPSqDKb2YbkSudZSUslLSX5lbV5xpC3AcYV1k3X/xzJyRqSE9zjGbdV6iqSzw9wYvq65pgHcOwUf99vkCTm4u/7uaLnb5IeK5I2l3S1pL70fX7Sz/sUGwe8nH6nBU8BveXiqtE660k6SdL9RfvuPf3EWfbz1rjsuJI4Kn6WSCrizyBJfi+k+7Sw/7cBbiiK/RGSBLpFmU01jBNBdotJvtSCrdNpkGT1Ut8BHiX5pTyK5GSjXCNca6vCk/TkvCVrY32TpDVUwZ+VrFvus/Q3/0rgQ8BfAW9GxJ1V1p8JnCBpP5Kip9vXbDjiWxGxJ0lx15+TFNOUeobk1/XoiOhJH6MiYud+4i5e/8midXsiYmREHFY0f7uM2yr1n8CBkrYEjmRtIqg15lqPneLv+53Apqz9vqu5kOT73DV9nw/38z7FFgObShpZNG1rknLygoEcS+tMl7QN8D2SMvrNIqIHeLCGOAfqWZL/m4KtKi0IEBFXRcQBJOeIICleheS7P7TkeNsoIvrof//UjRNBdjOB8ySNkTSapIz5J+m854HNJG1StPxIkkqyNyTtBHyijrHuKekoSRuQ/FJ5m6ScEpLL6hMldUk6BPjLGrf9PEm5+hrpiX81SeVa2auBIjeT/LP8M3BNesWCpL0k7SNpOEnx0VusbbZb/F7PAj8HviZplKRhkraTlPVz3A28JukcSd3pfniPpL3S+d8HLpC0gxK7Stqs0mcviW0JSbHeFSTJ5pEBxlzrsXOYpAMkjQAuIKmzyfJrfCRJJeVSSb2UT7xlpdv/LXChpI0k7Qp8jPQKL6Oq+zO1MckJcwmApI+SXBHk7Vrg05J6JfWQVAaXJWlHSQdL2pDkuF3G2mP3MuAraUIjPX9MTectIfm/6W8f5M6JILsvA/eStGaYT9Ia58sAEfEoSaJ4Ir0EHEdSSXsiSUXe90ha8dTLf5FUqr0C/B1wVESsSOd9GjiCpJL2QySVmLW4kCQhLpV0ZtH0HwG7sDY5lpUWJV1PUp56VdGsUST76RWSIoaXSOobyjmJpKL34XT5WSRlr/1Ki9iOIKncfJKkVcj3SVr1AHyd5CTwc5KT8Q9IrlwgufS/Mv3sx1Z4i6vKfLZaY6712LkK+CJJkdCeJN9rFl8C9iBppXUTyfdSixNIyrkXAzcAX4yIX9Sw/g+Aien+nF1ugYh4mOQHxp0kiWMX4I4a4xyI75EcA/OAuSQ/YFZS5scJST3ZRSTH0nMkRX6fS+d9k6Rl1c8lvU7yg2wfgIh4k6Se7I50H+yb26fphzuUtRlJ55NUJH64zu97EnByenlsddLpnbLqRdKhwGURsU2/C7cgXxHYoEl6B/BJYEajYzEbCmmx4WGSNkiLzb5IctXTlpwIbFAkTSEp63ye9YtDzFqVSIrOXiEpGnqEpF6wLbloyMysw/mKwMysw7XcoHOjR4+O8ePHNzoMM7OWct99970YEWPKzWu5RDB+/HjuvffeRodhZtZSJD1VaZ6LhszMOpwTgZlZh3MiMDPrcE4EZmYdzonAzKzDtVyrITOzTjN7bh+XzFnA4qXLGNfTzVlTdmTapN7+V8zIicDMrInNntvHudfPZ9mKZODTvqXLOPf6+QBDlgxcNGRm1sQumbNgTRIoWLZiFZfMWTBk7+FEYGbWxBYvXVbT9IFwIjAza2Ljerprmj4QTgRmZk3srCk70j28a51p3cO7OGvKjkP2Hq4sNjNrYoUK4bNnzWP5qtX0utWQmVnnmTapl5l3Pw3ANafsN+Tbd9GQmVmHcyIwM+twTgRmZh3OdQRm1vbyHqKh1TkRmFlbq8cQDa3OicDM2lqlIRrOnjVvTUucVvDws68xceyoXLbtOgIza2uVhmJYvmp1nSMZnIljRzF193yuYHK9IpB0CPBNoAv4fkRcVGG5vYC7gOMiYlaeMZlZZxnX001fmWTQ29OdS5v8VpTbFYGkLuBS4FBgInCCpIkVlrsYmJNXLGbWueoxREOry7NoaG9gYUQ8ERHLgauBqWWW+xRwHfBCjrGYWYeaNqmXC4/ahRFdyemut6ebC4/axRXFRfIsGuoFnil6vQjYp3gBSb3AkcDBwF6VNiTpZOBkgK233nrIAzWz9pb3EA2tLs8rApWZFiWvvwGcExGryiy7dqWIGRExOSImjxkzZqjiMzMz8r0iWARsVfR6S2BxyTKTgaslAYwGDpO0MiJm5xiXmbUBdxIbOnkmgnuAHSRNAPqA44ETixeIiAmF55J+CPzMScDM+uNOYkMrt0QQESslnUbSGqgLuDwiHpJ0ajr/srze28za20A6ieXZIavV5dqPICJuBm4umVY2AUTE3+cZi5m1j4F0EsuzQ1ar8xATZtZy3ElsaHmICTNrOe4kNrR8RWBmLace9/HtJE4EZtaS3Els6LhoyMysw/mKwMyaijuK1Z8TgZk1DXcUawwnAjNrGrV2FHMnsaHhOgIzaxq1dhRzJ7Gh4SsCM2sa7ijWGL4iMLOm4Y5ijeErAjNrGu4o1hhOBGbWVNxRrP6cCMxajNvZ21BzIjBrIW5nb3lwIjBrIQO5IUsrcv+A+nKrIbMWMpAbsrQi9w+oL18RmLUQt7O3PPiKwKyFuJ295cFXBGZ1MFQtfdzO3vLgRGCWs6Fu6eN29jbUnAjMcpZHSx+3qrGh1G8dgaTtJG2YPj9Q0umSenKPzKxN5NHSx61qbChluSK4DpgsaXvgB8CNwFXAYXkGZtYu3NLHml2WVkOrI2IlcCTwjYj4DDA237DM2odb+lizy3JFsELSCcBHgCPSacPzC8msPRS3FNqkezgrVq1m5epwSx9rOlkSwUeBU4GvRMSTkiYAP8k3LLPWVtpSaOmyFQwTbDd6Y24988DGBmdWot9EEBEPSzoH2Dp9/SRwUd6BmbWyci2FVgc880r5imOzRsrSaugI4H7glvT17pJuzDkus5bWKWMCWXvIUll8PrA3sBQgIu4HJuQWkVkbGNfTXXZ6b4XpZo2UJRGsjIhXS6ZFHsGYtQu3FLJWkqWy+EFJJwJdknYATgd+m29YZq3NYwJZK8mSCD4FfB54m6Qj2Rzgy3kGZdYOPCaQtYosiWDHiPg8STIwM7M2k6WO4OuSHpV0gaSdc4/IzMzqqt9EEBEHAQcCS4AZkuZLOi/vwMzMrD4y3aEsIp6LiG+R9DC+H/hClvUkHSJpgaSFkqaXmT9V0jxJ90u6V9IBtQRvVjB7bh/7X3QbE6bfxP4X3cbsuX2NDsmsZfRbRyDp3cBxwNHAS8DVwP/LsF4XcCnwAWARcI+kGyPi4aLFbgVujIiQtCtwLbBTzZ/COtpQ3/jFrNNkqSy+ApgJ/HVELK5h23sDCyPiCQBJVwNTgTWJICLeKFp+Y9w/wQYgjxu/DBXfQMZaQZaxhvYd4LZ7gWeKXi8C9ildSNKRwIXA5sDfDPC9rIM183AOvoGMtYIsRUM7kJyoJwIbFaZHxLb9rVpm2nq/+CPiBuAGSe8DLgDeXyaGk4GTAbbeeuv+QrY2Vu4m8L7xi9ngZKksvgL4DrASOAj4EfDjDOstArYqer0lULFoKSJ+DWwnaXSZeTMiYnJETB4zZkyGt7Z2VKgL6Fu6jGBtXcBBO43xcA5mg5AlEXRHxK2AIuKpiDgfODjDevcAO0iaIGkEcDzJbS7XkLS9JKXP9wBGkFRIm62nUl3AtfcsYtwmG625BO3t6ebCo3ZxRbFZRlkqi9+SNAx4TNJpQB9JeX5VEbEyXX4O0AVcHhEPSTo1nX8Z8EHgJEkrgGXAcRHhCmMrq1pdwOiRGzJ65IZM3b2XE/dx8aFZLbIkgjOAd5AMNncBSfHQR7JsPCJuBm4umXZZ0fOLgYszxmodznUBZvnI0rP4nrSZ5ysR8dGI+GBE3FWH2MzW4aGdzfKR5Q5l+0l6GHgkfb2bpG/nHplZiWmTernwqF0Y0ZUctq4LMBsaWYqGvgFMIa3ojYgH0qaeZnXnoZ3Nhl7WsYaeKZm0quyCZmbWcrJcETwj6b1ApM1ATyctJjIzs9aX5YrgVOCfSIaMWATsnr42M7M2kGWsoReBD9UhFjMza4CKiUDSv1NlNNCIOD2XiKwjlBszyK1/zBqj2hXBvXWLwjqK7x9g1lwqJoKIuLKegVjnGOz9AzzGv9nQytR81GwoDfb+AR7j32xoZWk+ajYkCvUClSqePGaQWWNUvCKQdHH695j6hWPtqvheAuV4zCCzxqlWNHSYpOHAufUKxtpXuXqBAo8ZZNZY1YqGbgFeBDaW9BrJrSej8DciXFtnmVWqFwC4Y3qW+xyZWV4qXhFExFkRsQlwU0SMioiRxX/rGKO1gXE93WWn91aYbmb1k+V+BFMlbSHp8PThmwZbzXwvAbPmleV+BMcAdwPHAMcCd0s6Ou/ArL34XgJmzStL89HzgL0i4gWA9Irgl8CsPAOz9uN7CZg1pywdyoYVkkDqpYzrmZlZC8hyRXCLpDnAzPT1cZTckN7MzFpXlsris4DvArsCuwEzIuKcvAOz9jN7bh9zn17K7558mf0vuo3Zc/saHZKZkXGIiYi4Hrg+51isjRV6FhfGE/KIo2bNw2X9VheVRhy9ZM6CBkVkZgVOBFYXlXoWV+txbGb1kaUfweGSnDBsUCr1LK403czqJ8sJ/njgMUlflfTuvAOy9uSexWbNK0uroQ8Dk4DHgSsk3SnpZEkjc4/O2oZ7Fps1r0xFPhHxGnAdcDUwFjgS+L2kT+UYm7WZaZN6mbR1D/tM2JQ7ph/sJGDWJLLUEfytpBuA24DhwN4RcShJn4Izc47PzMxylqUfwdHAv0XEr4snRsSbkv4hn7DMzKxeshQNPVuaBAq3sYyIW3OJyszM6ibLFcEHgNIhJQ4tM81sHYWb1S9euoxxPd1uIWTWpComAkmfAD4JbCdpXtGskcAdeQdmra0wpEShN3FhSIlxm2zE6JEbNjg6MytW7YrgKuB/gAuB6UXTX4+Il3ONylpepSElnnjxT04EZk2mWiKIiPijpH8qnSFpUycDK6dQHNRXYeiIAKbu7majZs2kvyuCw4H7SP5/VTQvgG1zjMtaUGlxUDm9Pd2cuM/WdYzKzPpTsdVQRBwuScBfRsS2ETGh6JEpCUg6RNICSQslTS8z/0OS5qWP30rabRCfxRqsXHFQMQ8pYdacqjYfjYgAbhjIhiV1AZeStDCaCJwgaWLJYk+SJJpdgQuAGQN5L2us2XP72P+i2yoWB4GHlDBrZlmaj94laa+IuKfGbe8NLIyIJwAkXQ1MBR4uLBARvy1+H2DLGt/DGixrcdAd0w+uY1RmVossHcoOAu6U9HhahDO/pDlpJb3AM0WvF6XTKvkYSSul9aSD3N0r6d4lS5ZkeGurFxcHmbW+LFcEhw5w2yozLcouKB1EkggOKDc/ImaQFhtNnjy57DasvvprHQTJlcBZU3Z0cZBZk8uSCAZ64l0EbFX0ektgcelCknYFvg8cGhEvDfC9rI5cHGTWXrIkgptY23x0I2ACsADYuZ/17gF2kDQB6CO5wc2JxQtI2hq4Hvi7iPhDbaFbo7g4yKy99JsIImKX4teS9gBOybDeSkmnAXOALuDyiHhI0qnp/MuALwCbAd9OWqqyMiIm1/wprK6q3WfYxUFmrSfLFcE6IuL3kvbKuOzNwM0l0y4rev5x4OO1xmCNNa6nu2zdgIuDzFpTv4lA0meLXg4D9gDcdKeDnTVlx/XqCFwcZNa6slwRFN+beCVJncF1+YRjrWLDDYatSQTvesdwvnjEzi4OMmtRWeoIvgQgaVTyMl7PPSprWuVaDL21YnUDIzKzwcpyz+LJkuYD84D5kh6QtGf+oVkzqjS89CVzFjQoIjMbrCxFQ5cDn4yI/wOQdABwBbBrnoFZc6rUYqhaSyIza25Zhph4vZAEACLiN4CLhzrUuJ7umqabWfPLkgjulvRdSQdK+ktJ3wZ+JWmPtE+BdZCzpuxI9/Cudaa5xZBZa8tSNLR7+veLJdPfS9Lj2A3HO0ihZdDZs+axfNVqdyAzawNZWg0dVI9ArHVMm9TLzLufBuCaU/ZrcDRmNlhZOpT1ACcB44uXj4jTc4vKzMzqJkvR0M0kN42ZD7jBeIcrHn56RNcwZs/tc7GQWYvLkgg2iojP9r+YtbvSzmTLV63m3OvnAzgZmLWwLK2GfizpHyWNlbRp4ZF7ZNZ03JnMrD1luSJYDlwCfJ61N6kJYNu8grLm5M5kZu0pSyL4LLB9RLyYdzDW3HreMZxX3lxRdrqZta4sRUMPAW/mHYg1v6hw09JK082sNWS5IlgF3C/pduDtwkQ3H+08ry5b/2qg2nQzaw1ZEsHs9GEdrtKdyTzOkFlry9Kz+Mp6BGLNz3cmM2tPFROBpGsj4tj0XgTrlQJHhIehbmOFjmOLly5jXMl4Qh5nyKy9VLsi+HT69/B6BGLNo7TjWN/SZet0HPM4Q2btpWIiiIhn079P1S8ca7TZc/v4f9c+wKqSpkDLVqzi7FnzmHn30zz87GtMHDuqQRGa2VDL0nzUOkThSqA0CRQsX5UMNTVx7Cim7u7iILN2kaXVkHWIckNIFOvt6XZxkFkb8hWBrVFtqAi3DjJrX9VaDZVtLQQICLcaaj+V+gl0SVx41C5uHWTWpqoVDbm1UIc5aKcx/PSup9fJ/t3Du5wEzNpctVZDbi3UQWbP7eO6+/rWSQICPrhnr5OAWZvrt45A0r6S7pH0hqTlklZJeq0ewVn9lKsoDuD2R5c0JiAzq5sslcX/AZwAPAZ0Ax8H/j3PoKz+fK8Bs86VqdVQRCwEuiJiVURcARyUb1hWb5UGjvOAcmbtL0sieFPSCJKhqL8q6TPAxjnHZXV21pQd6R7etc40Nxk16wxZEsHfpcudBvwJ2Ao4Ks+grP6mTerlg3uurRTuklxRbNYhsiSCaRHxVkS8FhFfiojP4qalbafQaqhgVQTX3dfH7Ll9VdYys3aQJRF8pMy0vx/iOKxBZs/tY/+LbuOMa+5fr9XQshWruGTOggZFZmb1Uq1n8QnAicAESTcWzRoFvJR3YJa/0uGmy3GrIbP2V61n8W+BZ4HRwNeKpr8OzMszKKuP/gaZA7caMusEFYuGIuKpiPhVROwHPAqMTB+LImJllo1LOkTSAkkLJU0vM38nSXdKelvSmQP9EDYw5cYVKuZWQ2adIUvP4mOAu4FjgGOB30k6OsN6XcClwKHAROAESRNLFnsZOB341xrjtkGaPbcPVZnf29PtMYbMOkSW+xGcB+wVES8ASBoD/BKY1c96ewMLI+KJdL2rganAw4UF0m2+IOlvBhC7DcIlcxZUHFr2347b3QnArINkaTU0rJAEUi9lXK8XeKbo9aJ0Ws0knSzpXkn3LlnisW+GQqVioQAnAbMOk+WK4BZJc4CZ6evjgP/JsF65kofy90DsR0TMAGYATJ48eUDbsHV1SWVvSdmlagVGZtaO+k0EEXGWpKOAA0hO7jMi4oYM215E0gu5YEtg8YCitAGbPbePS+YsYPHSZYzr6easKTsybVJvxfsSV5puZu2r30Qg6eKIOAe4vsy0au4BdpA0AegDjifpl2B1UtpPoG/pMs69fj6QVAaXKx7qdXNRs46Tpaz/A2WmHdrfSmkT09OAOcAjwLUR8ZCkUyWdCiDpzyQtAj4LnCdpkaRR2cO3asr1E1i2YhVnz5rHRhsMY1hJKZCbi5p1pmo9iz8BfBLYVlJxB7KRwB1ZNh4RNwM3l0y7rOj5cyRFRpaDShXCy1etZvTIDQF45pVlLF+1mt6iYiMz6yzVioauIqkUvhAo7gz2ekS8nGtUNiSGCVaXKfLvkrjmlP3qH5CZNaVq9yx+FXiV5O5k1mJmz+0rmwTAFcJmtq5Mdyiz1lNt1FBXCJtZMSeCNlVt1FBXCJtZMSeCNlVp1NCe7uGuEDazdTgRtKmDdhpTdvrhu42tcyRm1uycCNrU7Y+WH5Op0nQz61xOBG2qUh8C33HMzEo5EbShavca8B3HzKxUltFHrYmVG1Su2r0G3GLIzEo5EbSwSoPKVboPse81YGbluGiohVUaVK4SdyQzs3KcCFpYtZvPe2RRM8vKiaCFVbqbWJfE14/dnd6eboRvRG9m1bmOoIVVu8vYtEm9PvGbWSa+Imhh1a4IzMyyciJoYb7vsJkNBSeCFvaudwyvabqZWTmuI2gR5TqOVfrh7wsCM6uFE0ELqLXj2KvLVtQzPDNrcS4aagG1dhzzeEJmVgsnghbgjmNmlicnghbgjmNmlifXEbQAdxwzszz5iqAFVBoszoPImdlQcCJoAZXuP1xpuplZLZwIWsBN856tabqZWS1cR9AA5TqHVSvnf+XN8v0CKk03M6uFE0GdVeocBr57mJk1hhNBnVXqHHb2rHnMvPvpsut0CVaVaTjU0+0xhcxs8FxHUGeVOoctX7W64jrjN9t4vWnDh4nz/3bnIYvLzDqXrwjqrEsq2y+gS+KaU/aruF6t9QpmZlk5EdTZQO8h4I5jZpYXFw3V0ey5fVS6d5g7h5lZozgR1NElcxZQ7ne/wAPFmVnDOBHUUaWK4sBNR82scZwI6sg3mzezZpRrIpB0iKQFkhZKml5mviR9K50/T9IeecQxe24f+190GxOm38T+F93G7Ll9ebxNv3yzeTNrRrklAkldwKXAocBE4ARJE0sWOxTYIX2cDHxnqOMo9OTtW7qMYG1P3kYkA48iambNKM/mo3sDCyPiCQBJVwNTgYeLlpkK/CgiArhLUo+ksRExZKOpDaQnb1422mAYwwSriy4AfEcxM2u0PIuGeoFnil4vSqfVugySTpZ0r6R7lyxZUlMQiwfQkzcvo0duyITNNmZEV7LbfUcxM2sGeV4RlKsBLS0Mz7IMETEDmAEwefLkmgrUx/V0l22t09vTXbUnr5lZp8jzimARsFXR6y2BxQNYZlDOmrIj3cO71pnm4hgzs7XyTAT3ADtImiBpBHA8cGPJMjcCJ6Wth/YFXh3K+gFI2udfeNQuvsG7mVkFuRUNRcRKSacBc4Au4PKIeEjSqen8y4CbgcOAhcCbwEfziMXj9JiZVZbroHMRcTPJyb542mVFzwP4pzxjMDOz6tyz2MyswzkRmJl1OCcCM7MO50RgZtbhFC024JmkJcBTA1x9NPDiEIbTqrwfvA/A+wA6ax9sExFjys1ouUQwGJLujYjJjY6j0bwfvA/A+wC8DwpcNGRm1uGcCMzMOlynJYIZjQ6gSXg/eB+A9wF4HwAdVkdgZmbr67QrAjMzK+FEYGbW4Vo6EUg6RNICSQslTS8zX5K+lc6fJ2mP/taVtKmkX0h6LP37rnp9noHIaR+cL6lP0v3p47B6fZ6BGOQ+uFzSC5IeLFmnk46DSvugI44DSVtJul3SI5IekvTponVa6jgYsIhoyQfJ0NaPA9sCI4AHgIklyxwG/A/JndD2BX7X37rAV4Hp6fPpwMWN/qwN2AfnA2c2+vPlvQ/See8D9gAeLFmnI46DfvZBRxwHwFhgj/T5SOAPrXg+GMyjla8I9gYWRsQTEbEcuBqYWrLMVOBHkbgL6JE0tp91pwJXps+vBKbl/DkGI6990EoGsw+IiF8DL5fZbqccB9X2QSsZ8D6IiGcj4vcAEfE68Ahr753eSsfBgLVyIshy4/tKy1Rbd4tI75KW/t18CGMeanntA4DT0svny5v8cngw+6CaTjkO+tNRx4Gk8cAk4HfppFY6DgaslRNBlhvfV1omy7qtIK998B1gO2B34FngawOMrx4Gsw/aRV77oKOOA0nvBK4DzoiI14YwtqbXyokgy43vKy1Tbd3nC5fM6d8XhjDmoZbLPoiI5yNiVUSsBr5HctndrAazD6rplOOgok46DiQNJ0kCP42I64uWaaXjYMBaORHcA+wgaYKkEcDxwI0ly9wInJS2FtgXeDW9vKu27o3AR9LnHwH+K+8PMgi57IPCgZ86EniQ5jWYfVBNpxwHFXXKcSBJwA+ARyLi62XWaZXjYOAaXVs9mAdJK4A/kLQW+Hw67VTg1PS5gEvT+fOBydXWTadvBtwKPJb+3bTRn7MB++DH6bLzSP4Rxjb6c+a4D2aSFHusIPnF+LEOPA4q7YOOOA6AA0iKiOYB96ePw1rxOBjow0NMmJl1uFYuGjIzsyHgRGBm1uGcCMzMOpwTgZlZh3MiMDPrcE4E1nYkHZOOJHl7+npmOkzCZ2rcTo+kTxa9Hidp1lDHW/KebwzFMma1cPNRazuSbiEZJfJ2SX9GMsrkNgPYznjgZxHxnqGOscp7vhER7xzsMma18BWBtSxJH5Z0dzpW/ncldUn6AkkHocskXQL8HNg8XeYvJG0n6RZJ90n6P0k7pdvaQtINkh5IH+8FLgK2S9e9RNJ4pWP2S/qdpJ2LYvmVpD0lbZwO0HaPpLmS1hvRVdI7Jd0q6feS5ldY5kBJv05jeljSZZKGFc3/ShrnXZK2SKcdkcY1V9IvC9PN+tXoHm1++DGQB/Bu4L+B4enrbwMnpc9/xdpeo+MpGmefpHfoDunzfYDb0ufXkAw2BsnY9puUWXfNa+AzwJfS52OBP6TP/wX4cPq8h6Sn68YlsW8AjEqfjwYWsvbq/I3074HAWyTj63cBvwCOTucFcET6/KvAeenzdxVt5+PA1xr9PfnRGo8NBpQ9zBrvr4A9gXuSoWLopp8BwZSMLvle4D/TdQA2TP8eDJwEEBGrgFdVfdjla0lOzl8EjgX+M53+18DfSjozfb0RsDXJGPdrQgH+RdL7gNUkQyFvATxX8h53R8QTaewzSa50ZgHLgZ+ly9wHfCB9viVwTTpG0AjgySrxm63hRGCtSsCVEXFuDesMA5ZGxO6DffOI6JP0kqRdgeOAU4ri+mBELKiy+oeAMcCeEbFC0h9JEsZ6b1Ph9YqIKDxfxdr/438Hvh4RN0o6kOQOY2b9ch2BtapbgaMlbQ5r7i1btUI4kjHmn5R0TLqOJO1WtL1PpNO7JI0CXie5dWElVwNnA5tExPx02hzgU+mIlkiaVGa9TYAX0iRwEFAp7r3T0TSHkSSb31T7fOl2+9LnH6m2oFkxJwJrSRHxMHAe8HNJ80iKacZWXwtIfo1/TNIDwEOsvZ3hp4GDJM0nKW7ZOSJeAu6Q9GBa8VxqFslwx9cWTbsAGA7MSyuWLyiz3k+ByZLuTeN5tEKsd5JUWD9IUsxzQz+f7XySYq//A17sZ1mzNdx81KwJpUU7Z0bE4Q0OxTqArwjMzDqcrwjMzDqcrwjMzDqcE4GZWYdzIjAz63BOBGZmHc6JwMysw/1/VLAyYFErAIoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(ccp_alphas[:-1], impurities[:-1], marker='o', drawstyle=\"steps-post\")\n",
    "ax.set_xlabel(\"effective alpha\")\n",
    "ax.set_ylabel(\"total impurity of leaves\")\n",
    "ax.set_title(\"Total Impurity vs effective alpha for training set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "id": "9a3d00aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.650 (0.038)\n"
     ]
    }
   ],
   "source": [
    "model_dt = DecisionTreeClassifier(ccp_alpha = 0.010, max_features = 'log2')\n",
    "model_dt.fit(X_train2, y_train2)\n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=35)\n",
    "n_scores = cross_val_score(model_dt, Sampled_Dummy_Data.drop(columns='Attrition',axis=1), Sampled_Dummy_Data['Attrition'], scoring='accuracy')\n",
    "# report performance\n",
    "print('Accuracy : %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "id": "6c347df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7633802816901408\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(model_dt.score(X_train2, y_train2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "id": "a66472be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 0.7633802816901408\n"
     ]
    }
   ],
   "source": [
    "# Check the model performance with the training data\n",
    "predictions_dt = model_dt.predict(X_train2)\n",
    "print(\"DecisionTreeClassifier\", accuracy_score(y_train2, predictions_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "id": "f2791687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score :  0.6470588235294118\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.73      0.67        59\n",
      "           1       0.68      0.57      0.62        60\n",
      "\n",
      "    accuracy                           0.65       119\n",
      "   macro avg       0.65      0.65      0.65       119\n",
      "weighted avg       0.65      0.65      0.64       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions_dt = model_dt.predict(X_test2)\n",
    "print(\"Testing Score : \", accuracy_score(y_test2, predictions_dt))\n",
    "print(classification_report(y_test2, predictions_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55d2c15",
   "metadata": {},
   "source": [
    "### E.  Random Forest Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "id": "c69456a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8338028169014085\n",
      "Accuracy : 0.745 (0.038)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.66      0.67        59\n",
      "           1       0.67      0.68      0.68        60\n",
      "\n",
      "    accuracy                           0.67       119\n",
      "   macro avg       0.67      0.67      0.67       119\n",
      "weighted avg       0.67      0.67      0.67       119\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_RFC = RandomForestClassifier(ccp_alpha=0.015)\n",
    "# fit the model on the whole dataset\n",
    "model_RFC.fit(X_train2, y_train2)\n",
    "print(model_RFC.score(X_train2, y_train2))\n",
    "# evaluate the model\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=35)\n",
    "n_scores = cross_val_score(model_RFC, Sampled_Dummy_Data.drop(columns='Attrition',axis=1), Sampled_Dummy_Data['Attrition'], scoring='accuracy')\n",
    "# report performance\n",
    "print('Accuracy : %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))\n",
    "y_pred_RFC = model_RFC.predict(X_test2)\n",
    "print(classification_report(y_test2, y_pred_RFC))\n",
    "# train, test = train_test_split(n_df, test_size=0.2)\n",
    "# train, val= train_test_split(train, test_size=0.25)\n",
    "# cv=CountVectorizer()\n",
    "# features=cv.fit_tranform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "648aae59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier 0.6722689075630253\n"
     ]
    }
   ],
   "source": [
    "predictions = model_RFC.predict(X_test2)\n",
    "print(\"RandomForestClassifier\", accuracy_score(y_test2, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "f0240fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.577 (0.071)\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(estimator=RandomForestClassifier(), n_features_to_select=5)\n",
    "model_dt_rfe = RandomForestClassifier()\n",
    "pipeline = Pipeline(steps=[('s',rfe),('m',model_dt_rfe)])\n",
    "# evaluate model\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "n_scores = cross_val_score(pipeline, SampledData.drop(columns='Attrition',axis=1), SampledData['Attrition'], scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "# report performance\n",
    "print('Accuracy: %.3f (%.3f)' % (np.mean(n_scores), np.std(n_scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6aea02",
   "metadata": {},
   "source": [
    "### F. xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "c681be26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abdul\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01:40:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "1.0\n",
      "Test :  0.6890756302521008\n"
     ]
    }
   ],
   "source": [
    "# xgboost\n",
    "model_XGB = XGBClassifier()\n",
    "model_XGB.fit(X_train2, y_train2)\n",
    "print(model_XGB.score(X_train2, y_train2))\n",
    "\n",
    "predictions_XGB = model_XGB.predict(X_test2)\n",
    "print(\"Test : \", accuracy_score(y_test2, predictions_XGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "c296742a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.69\n"
     ]
    }
   ],
   "source": [
    "y_pred = model_XGB.predict(X_test2)\n",
    "predictions = [value for value in y_pred]\n",
    "accuracy = accuracy_score(y_test2, predictions)\n",
    "print(\"Accuracy: %.2f\" % (accuracy ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05696433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55744169",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
